{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-06T11:39:41.188365Z",
     "iopub.status.busy": "2025-03-06T11:39:41.188027Z",
     "iopub.status.idle": "2025-03-06T11:39:45.333555Z",
     "shell.execute_reply": "2025-03-06T11:39:45.332685Z",
     "shell.execute_reply.started": "2025-03-06T11:39:41.188343Z"
    },
    "id": "F5lFnAMI-XAg",
    "outputId": "29e39f80-715a-4e24-a552-3bb5477ab3ec",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.19)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
      "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
      "Requirement already satisfied: langchainhub in /usr/local/lib/python3.10/dist-packages (0.1.21)\n",
      "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.6.3)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.20)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.41)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.12)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.8.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.3)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.65.4)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (24.2)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (2.32.0.20250306)\n",
      "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.11.0a2)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.115.11)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.18.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (5.13.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.68.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.12)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.2.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.46.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain_community) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain_community) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain_community) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain_community) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain_community) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain_community) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain_community) (2.4.1)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.30.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.29.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.29.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.12.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3,>=1.26.2->langchain_community) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3,>=1.26.2->langchain_community) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.26.2->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3,>=1.26.2->langchain_community) (2024.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3,>=1.26.2->langchain_community) (2024.2.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "# Tiktoken is an open-source Python library that breaks text into tokens\n",
    "#Langchian_community sued to make returiever\n",
    "#Used chromaDB for database\n",
    "\n",
    "!pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "execution": {
     "iopub.execute_input": "2025-03-06T11:39:46.445237Z",
     "iopub.status.busy": "2025-03-06T11:39:46.444755Z",
     "iopub.status.idle": "2025-03-06T11:39:46.452479Z",
     "shell.execute_reply": "2025-03-06T11:39:46.451470Z",
     "shell.execute_reply.started": "2025-03-06T11:39:46.445194Z"
    },
    "id": "TvoyHFvJ-W8G",
    "outputId": "686fb787-55d6-4b62-c272-d0c88e9b7ccc",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.20'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T11:39:48.358850Z",
     "iopub.status.busy": "2025-03-06T11:39:48.358506Z",
     "iopub.status.idle": "2025-03-06T11:39:48.363465Z",
     "shell.execute_reply": "2025-03-06T11:39:48.362515Z",
     "shell.execute_reply.started": "2025-03-06T11:39:48.358824Z"
    },
    "id": "EcS2MW5N-W26",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#create .env and add OPENAI_API_KEY, LANGCHAIN_API_KEY\n",
    "\n",
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T11:39:51.967974Z",
     "iopub.status.busy": "2025-03-06T11:39:51.967667Z",
     "iopub.status.idle": "2025-03-06T11:39:51.973174Z",
     "shell.execute_reply": "2025-03-06T11:39:51.972221Z",
     "shell.execute_reply.started": "2025-03-06T11:39:51.967950Z"
    },
    "id": "TFicherm-Wyu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-06T11:39:55.215959Z",
     "iopub.status.busy": "2025-03-06T11:39:55.215639Z",
     "iopub.status.idle": "2025-03-06T11:39:57.372273Z",
     "shell.execute_reply": "2025-03-06T11:39:57.371404Z",
     "shell.execute_reply.started": "2025-03-06T11:39:55.215933Z"
    },
    "id": "c7kFd5ap-WuM",
    "outputId": "eddabba0-1111-4175-9806-1c4ff9180610",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Reference values in lab test reports are typically calculated based on a large sample of healthy individuals. These individuals are usually selected to be representative of the general population in terms of age, sex, and other relevant factors. The reference values are then determined by calculating the range of values that encompass the majority of these healthy individuals.\\n\\nIn some cases, reference values may also be adjusted based on specific factors such as age, sex, or ethnicity. This is done to account for variations in normal values that may occur in different populations.\\n\\nIt is important to note that reference values are not set in stone and may vary slightly between different laboratories and testing methods. Additionally, reference values are meant to be used as a general guide and should be interpreted in conjunction with other clinical information to make an accurate diagnosis.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 157, 'prompt_tokens': 18, 'total_tokens': 175, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7474bd31-1833-464b-87fa-3c5a1447f9c3-0', usage_metadata={'input_tokens': 18, 'output_tokens': 157, 'total_tokens': 175, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "med_llm = llm.invoke(\"Tell me how are reference values calculated in lab test reports\")\n",
    "med_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "execution": {
     "iopub.execute_input": "2025-03-06T11:40:01.663028Z",
     "iopub.status.busy": "2025-03-06T11:40:01.662665Z",
     "iopub.status.idle": "2025-03-06T11:40:01.670355Z",
     "shell.execute_reply": "2025-03-06T11:40:01.669539Z",
     "shell.execute_reply.started": "2025-03-06T11:40:01.662998Z"
    },
    "id": "Hhs3BzDv-WYO",
    "outputId": "9a79d291-f9a6-455b-98c0-64a1296c8792",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reference values in lab test reports are typically calculated based on a large sample of healthy individuals. These individuals are usually selected to be representative of the general population in terms of age, sex, and other relevant factors. The reference values are then determined by calculating the range of values that encompass the majority of these healthy individuals.\\n\\nIn some cases, reference values may also be adjusted based on specific factors such as age, sex, or ethnicity. This is done to account for variations in normal values that may occur in different populations.\\n\\nIt is important to note that reference values are not set in stone and may vary slightly between different laboratories and testing methods. Additionally, reference values are meant to be used as a general guide and should be interpreted in conjunction with other clinical information to make an accurate diagnosis.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OutputParser for getting only the output\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "output_parser.invoke(med_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T11:40:33.173948Z",
     "iopub.status.busy": "2025-03-06T11:40:33.173618Z",
     "iopub.status.idle": "2025-03-06T11:40:33.178121Z",
     "shell.execute_reply": "2025-03-06T11:40:33.177095Z",
     "shell.execute_reply.started": "2025-03-06T11:40:33.173923Z"
    },
    "id": "Q0Cw5qCdaOP8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T11:40:35.301969Z",
     "iopub.status.busy": "2025-03-06T11:40:35.301626Z",
     "iopub.status.idle": "2025-03-06T11:40:36.027217Z",
     "shell.execute_reply": "2025-03-06T11:40:36.025459Z",
     "shell.execute_reply.started": "2025-03-06T11:40:35.301938Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load pre-trained BlueBERT model and tokenizer\n",
    "model_name = \"bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T11:40:44.475636Z",
     "iopub.status.busy": "2025-03-06T11:40:44.475248Z",
     "iopub.status.idle": "2025-03-06T11:40:44.481282Z",
     "shell.execute_reply": "2025-03-06T11:40:44.480118Z",
     "shell.execute_reply.started": "2025-03-06T11:40:44.475598Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Sample conversation\n",
    "conversation = \"\"\"\n",
    "Patient: Hi, I’ve been feeling unwell for the past few days.\n",
    "Patient: I’ve had a fever for the past three days, along with a sore throat and body aches.\n",
    "Patient: I do have a mild cough, and my throat feels dry. But I don’t have any nausea or difficulty breathing.\n",
    "Patient: No, I haven’t traveled, but a few of my colleagues at work had a cold last week.\n",
    "Patient: No, I don’t have any chronic illnesses, and I’m not allergic to anything.\n",
    "Patient: I took a paracetamol yesterday for the fever, and I’ve been drinking warm water and resting.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T11:40:52.697651Z",
     "iopub.status.busy": "2025-03-06T11:40:52.697299Z",
     "iopub.status.idle": "2025-03-06T11:40:52.704549Z",
     "shell.execute_reply": "2025-03-06T11:40:52.703773Z",
     "shell.execute_reply.started": "2025-03-06T11:40:52.697628Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the conversation\n",
    "inputs = tokenizer(conversation, return_tensors=\"pt\", truncation=True, padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T11:41:01.695851Z",
     "iopub.status.busy": "2025-03-06T11:41:01.695532Z",
     "iopub.status.idle": "2025-03-06T11:41:01.905069Z",
     "shell.execute_reply": "2025-03-06T11:41:01.904055Z",
     "shell.execute_reply.started": "2025-03-06T11:41:01.695826Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get model embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state  # Shape: (batch_size, seq_length, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T11:41:09.241881Z",
     "iopub.status.busy": "2025-03-06T11:41:09.241566Z",
     "iopub.status.idle": "2025-03-06T11:41:09.302501Z",
     "shell.execute_reply": "2025-03-06T11:41:09.301804Z",
     "shell.execute_reply.started": "2025-03-06T11:41:09.241856Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6700,  0.0529, -0.0106,  ...,  0.0439,  0.3718,  0.1110],\n",
       "         [-0.8095,  0.0119, -0.5421,  ..., -0.1386,  0.1275, -0.2058],\n",
       "         [-0.3707,  0.1895,  0.0814,  ..., -0.3273,  0.5411,  0.0334],\n",
       "         ...,\n",
       "         [ 0.5727,  0.7360,  0.2596,  ...,  0.3456,  0.1816, -0.1227],\n",
       "         [-0.0589,  0.0079,  0.2925,  ...,  0.2673,  0.8035, -0.5467],\n",
       "         [ 0.9751,  0.1525, -0.1767,  ..., -0.2151,  0.5104, -0.0517]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T11:41:15.770289Z",
     "iopub.status.busy": "2025-03-06T11:41:15.769850Z",
     "iopub.status.idle": "2025-03-06T11:41:15.774933Z",
     "shell.execute_reply": "2025-03-06T11:41:15.773963Z",
     "shell.execute_reply.started": "2025-03-06T11:41:15.770253Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "keywords = {\n",
    "    \"symptoms\": [\"fever\", \"sore throat\", \"body aches\", \"cough\", \"headache\", \"nausea\", \"difficulty breathing\"],\n",
    "    \"exposure\": [\"contact\", \"sick\", \"colleagues\", \"traveled\"],\n",
    "    \"medical_history\": [\"diabetes\", \"high blood pressure\", \"asthma\", \"allergies\", \"chronic illness\"],\n",
    "    \"medications\": [\"paracetamol\", \"ibuprofen\", \"antibiotic\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T11:41:24.095575Z",
     "iopub.status.busy": "2025-03-06T11:41:24.095242Z",
     "iopub.status.idle": "2025-03-06T11:41:24.101709Z",
     "shell.execute_reply": "2025-03-06T11:41:24.100691Z",
     "shell.execute_reply.started": "2025-03-06T11:41:24.095548Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Medical Information:\n",
      "Symptoms: fever, sore throat, body aches, cough, nausea, difficulty breathing\n",
      "Exposure: colleagues, traveled\n",
      "Medical_history: chronic illness\n",
      "Medications: paracetamol\n"
     ]
    }
   ],
   "source": [
    "# Extract detected keywords\n",
    "extracted_info = {key: [] for key in keywords}\n",
    "for key, values in keywords.items():\n",
    "    for word in values:\n",
    "        if word in conversation.lower():\n",
    "            extracted_info[key].append(word)\n",
    "\n",
    "# Print extracted details\n",
    "print(\"Extracted Medical Information:\")\n",
    "for category, details in extracted_info.items():\n",
    "    print(f\"{category.capitalize()}: {', '.join(details) if details else 'None found'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langchain Based Approach for not hardcoding the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T11:41:59.565802Z",
     "iopub.status.busy": "2025-03-06T11:41:59.565472Z",
     "iopub.status.idle": "2025-03-06T11:42:03.874596Z",
     "shell.execute_reply": "2025-03-06T11:42:03.873176Z",
     "shell.execute_reply.started": "2025-03-06T11:41:59.565778Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T11:42:13.246699Z",
     "iopub.status.busy": "2025-03-06T11:42:13.246271Z",
     "iopub.status.idle": "2025-03-06T11:42:13.252093Z",
     "shell.execute_reply": "2025-03-06T11:42:13.250984Z",
     "shell.execute_reply.started": "2025-03-06T11:42:13.246662Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T11:42:26.132137Z",
     "iopub.status.busy": "2025-03-06T11:42:26.131765Z",
     "iopub.status.idle": "2025-03-06T11:42:26.136508Z",
     "shell.execute_reply": "2025-03-06T11:42:26.135524Z",
     "shell.execute_reply.started": "2025-03-06T11:42:26.132104Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set OpenAI API Key (Replace with your actual API key)\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T11:42:34.680309Z",
     "iopub.status.busy": "2025-03-06T11:42:34.679777Z",
     "iopub.status.idle": "2025-03-06T11:42:35.309401Z",
     "shell.execute_reply": "2025-03-06T11:42:35.308319Z",
     "shell.execute_reply.started": "2025-03-06T11:42:34.680275Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load OpenAI model via LangChain\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T11:42:48.247967Z",
     "iopub.status.busy": "2025-03-06T11:42:48.247670Z",
     "iopub.status.idle": "2025-03-06T11:42:48.952099Z",
     "shell.execute_reply": "2025-03-06T11:42:48.950128Z",
     "shell.execute_reply.started": "2025-03-06T11:42:48.247944Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load BlueBERT model and tokenizer\n",
    "model_name = \"bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T11:42:56.777029Z",
     "iopub.status.busy": "2025-03-06T11:42:56.776636Z",
     "iopub.status.idle": "2025-03-06T11:42:56.783008Z",
     "shell.execute_reply": "2025-03-06T11:42:56.781788Z",
     "shell.execute_reply.started": "2025-03-06T11:42:56.776994Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to extract medical information using LangChain\n",
    "def extract_medical_info(conversation):\n",
    "    prompt = f\"\"\"\n",
    "    Extract relevant medical information from the following conversation.\n",
    "    Categorize the extracted details under:\n",
    "    - Symptoms\n",
    "    - Exposure\n",
    "    - Medical History\n",
    "    - Medications\n",
    "\n",
    "    Only return structured JSON format without extra explanations.\n",
    "\n",
    "    Conversation:\n",
    "    \\\"\\\"\\\"{conversation}\\\"\\\"\\\"\n",
    "\n",
    "    Output:\n",
    "    {{\n",
    "        \"symptoms\": [],\n",
    "        \"exposure\": [],\n",
    "        \"medical_history\": [],\n",
    "        \"medications\": []\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are an AI assistant specialized in medical text processing.\"),\n",
    "        HumanMessage(content=prompt)\n",
    "    ]\n",
    "\n",
    "    response = llm(messages)\n",
    "\n",
    "    # Parse JSON output\n",
    "    extracted_info = json.loads(response.content)\n",
    "    return extracted_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T11:43:05.819334Z",
     "iopub.status.busy": "2025-03-06T11:43:05.818972Z",
     "iopub.status.idle": "2025-03-06T11:43:05.823956Z",
     "shell.execute_reply": "2025-03-06T11:43:05.823067Z",
     "shell.execute_reply.started": "2025-03-06T11:43:05.819307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to generate BlueBERT embeddings\n",
    "def get_bluebert_embedding(text):\n",
    "    if not text:\n",
    "        return None  # Return None if there's no relevant information in a category\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Extract the sentence-level embedding (mean of last hidden state)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T11:43:17.875347Z",
     "iopub.status.busy": "2025-03-06T11:43:17.874934Z",
     "iopub.status.idle": "2025-03-06T11:43:19.416816Z",
     "shell.execute_reply": "2025-03-06T11:43:19.416069Z",
     "shell.execute_reply.started": "2025-03-06T11:43:17.875315Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-58-5f91abaf7f2f>:30: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm(messages)\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Medical Information:\n",
      "{\n",
      "  \"symptoms\": [\n",
      "    \"fever\",\n",
      "    \"sore throat\",\n",
      "    \"body aches\",\n",
      "    \"mild cough\",\n",
      "    \"dry throat\"\n",
      "  ],\n",
      "  \"exposure\": [\n",
      "    \"colleagues at work had a cold last week\"\n",
      "  ],\n",
      "  \"medical_history\": [\n",
      "    \"no chronic illnesses\",\n",
      "    \"not allergic to anything\"\n",
      "  ],\n",
      "  \"medications\": [\n",
      "    \"paracetamol\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "Generated BlueBERT Embeddings:\n",
      "Symptoms Embedding Shape: (768,)\n",
      "Exposure Embedding Shape: (768,)\n",
      "Medical_history Embedding Shape: (768,)\n",
      "Medications Embedding Shape: (768,)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extract Medical Information Using LangChain\n",
    "extracted_info = extract_medical_info(conversation)\n",
    "\n",
    "# Step 2: Generate BlueBERT embeddings for each category\n",
    "embeddings = {category: get_bluebert_embedding(\" \".join(terms)) for category, terms in extracted_info.items() if terms}\n",
    "\n",
    "# Print extracted info and corresponding embeddings\n",
    "print(\"\\nExtracted Medical Information:\")\n",
    "print(json.dumps(extracted_info, indent=2))\n",
    "\n",
    "print(\"\\nGenerated BlueBERT Embeddings:\")\n",
    "for category, embedding in embeddings.items():\n",
    "    print(f\"{category.capitalize()} Embedding Shape: {embedding.shape if embedding is not None else 'No Data'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T11:55:34.317509Z",
     "iopub.status.busy": "2025-03-06T11:55:34.316981Z",
     "iopub.status.idle": "2025-03-06T11:55:34.322314Z",
     "shell.execute_reply": "2025-03-06T11:55:34.320753Z",
     "shell.execute_reply.started": "2025-03-06T11:55:34.317465Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T11:58:29.089188Z",
     "iopub.status.busy": "2025-03-06T11:58:29.088809Z",
     "iopub.status.idle": "2025-03-06T11:58:29.099721Z",
     "shell.execute_reply": "2025-03-06T11:58:29.098640Z",
     "shell.execute_reply.started": "2025-03-06T11:58:29.089157Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symptoms Embedding Shape: torch.Size([1, 768])\n",
      "exposure Embedding Shape: torch.Size([1, 768])\n",
      "medical_history Embedding Shape: torch.Size([1, 768])\n",
      "medications Embedding Shape: torch.Size([1, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-71-f4f4bb303d32>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  conversation_data = torch.load(\"/kaggle/working/conversation_embeddings.pt\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load saved conversation embeddings\n",
    "conversation_data = torch.load(\"/kaggle/working/conversation_embeddings.pt\")\n",
    "\n",
    "# Convert conversation embeddings to (1, 768) shape\n",
    "for category, embedding in conversation_data[\"embeddings\"].items():\n",
    "    if isinstance(embedding, torch.Tensor) and len(embedding.shape) == 1:  # Ensure it's a 1D tensor (768,)\n",
    "        conversation_data[\"embeddings\"][category] = embedding.unsqueeze(0)  # Convert to (1, 768)\n",
    "\n",
    "# Verify changes\n",
    "for category, embedding in conversation_data[\"embeddings\"].items():\n",
    "    print(f\"{category} Embedding Shape: {embedding.shape}\")  # Should now be (1, 768)\n",
    "\n",
    "# Save back the modified embeddings if needed\n",
    "torch.save(conversation_data, \"/kaggle/working/conversation_embeddings.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T12:00:02.138572Z",
     "iopub.status.busy": "2025-03-06T12:00:02.138198Z",
     "iopub.status.idle": "2025-03-06T12:00:02.145433Z",
     "shell.execute_reply": "2025-03-06T12:00:02.144441Z",
     "shell.execute_reply.started": "2025-03-06T12:00:02.138544Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated conversation embeddings saved successfully!\n"
     ]
    }
   ],
   "source": [
    "torch.save(conversation_data, \"/kaggle/working/conversation_embeddings_updated.pt\")\n",
    "print(\"Updated conversation embeddings saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T12:00:55.803615Z",
     "iopub.status.busy": "2025-03-06T12:00:55.803244Z",
     "iopub.status.idle": "2025-03-06T12:00:55.812219Z",
     "shell.execute_reply": "2025-03-06T12:00:55.811233Z",
     "shell.execute_reply.started": "2025-03-06T12:00:55.803589Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symptoms Embedding Shape: torch.Size([1, 768])\n",
      "exposure Embedding Shape: torch.Size([1, 768])\n",
      "medical_history Embedding Shape: torch.Size([1, 768])\n",
      "medications Embedding Shape: torch.Size([1, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-74-308e89dd1ed5>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  conversation_data_loaded = torch.load(\"/kaggle/working/conversation_embeddings_updated.pt\")\n"
     ]
    }
   ],
   "source": [
    "# Load the updated embeddings\n",
    "conversation_data_loaded = torch.load(\"/kaggle/working/conversation_embeddings_updated.pt\")\n",
    "\n",
    "# Print the shapes to verify they are still (1, 768)\n",
    "for category, embedding in conversation_data_loaded[\"embeddings\"].items():\n",
    "    print(f\"{category} Embedding Shape: {embedding.shape}\")  # Should be (1, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T11:58:36.732592Z",
     "iopub.status.busy": "2025-03-06T11:58:36.732231Z",
     "iopub.status.idle": "2025-03-06T11:58:36.738479Z",
     "shell.execute_reply": "2025-03-06T11:58:36.737386Z",
     "shell.execute_reply.started": "2025-03-06T11:58:36.732567Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symptoms Embedding Shape: (768,)\n",
      "Exposure Embedding Shape: (768,)\n",
      "Medical_history Embedding Shape: (768,)\n",
      "Medications Embedding Shape: (768,)\n"
     ]
    }
   ],
   "source": [
    "for category, embedding in embeddings.items():\n",
    "    print(f\"{category.capitalize()} Embedding Shape: {embedding.shape if embedding is not None else 'No Data'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T11:45:34.803966Z",
     "iopub.status.busy": "2025-03-06T11:45:34.803508Z",
     "iopub.status.idle": "2025-03-06T11:45:36.316480Z",
     "shell.execute_reply": "2025-03-06T11:45:36.315657Z",
     "shell.execute_reply.started": "2025-03-06T11:45:34.803930Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation embeddings saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Extract Medical Information Using LangChain\n",
    "extracted_info = extract_medical_info(conversation)\n",
    "\n",
    "# Step 2: Generate BlueBERT embeddings for each category\n",
    "embeddings = {category: get_bluebert_embedding(\" \".join(terms)) for category, terms in extracted_info.items() if terms}\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors before saving\n",
    "conversation_data = {\n",
    "    \"extracted_info\": extracted_info,  # Raw extracted medical data\n",
    "    \"embeddings\": {category: torch.tensor(embedding) if isinstance(embedding, np.ndarray) else embedding for category, embedding in embeddings.items() if embedding is not None}\n",
    "}\n",
    "\n",
    "# Save as a PyTorch .pt file\n",
    "torch.save(conversation_data, \"conversation_embeddings.pt\")\n",
    "\n",
    "# Save as a Pickle .pkl file\n",
    "with open(\"conversation_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(conversation_data, f)\n",
    "\n",
    "print(\"Conversation embeddings saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6803952,
     "sourceId": 10940629,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
