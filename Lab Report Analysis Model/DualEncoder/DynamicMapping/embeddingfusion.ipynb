{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":277142,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":237351,"modelId":259035}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\n\n# Load saved embeddings\nlab_test_embeddings = torch.load(\"/kaggle/input/labreportandconversationembeddings/pytorch/default/1/lab_icd_embeddings.pt\")  # Lab report embeddings\nconversation_data = torch.load(\"/kaggle/input/labreportandconversationembeddings/pytorch/default/1/conversation_embeddings_updated.pt\")  # Conversation embeddings\n\n# Verify shapes before proceeding\nfor test, info in lab_test_embeddings.items():\n    print(f\"Lab Test: {test} | Embedding Shape: {info['lab_test_embedding'].shape}\")\n\nfor category, embedding in conversation_data[\"embeddings\"].items():\n    print(f\"{category} Embedding Shape: {embedding.shape}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-06T12:19:43.526531Z","iopub.execute_input":"2025-03-06T12:19:43.526881Z","iopub.status.idle":"2025-03-06T12:19:43.544745Z","shell.execute_reply.started":"2025-03-06T12:19:43.526856Z","shell.execute_reply":"2025-03-06T12:19:43.543345Z"}},"outputs":[{"name":"stdout","text":"Lab Test: The lab tests mentioned in the report are:\n\n1. Lipid Profile | Embedding Shape: torch.Size([1, 768])\nLab Test: Basic | Embedding Shape: torch.Size([1, 768])\nLab Test: Serum\n2. HbA1c (Glycosylated Hemoglobin) | Embedding Shape: torch.Size([1, 768])\nLab Test: Blood | Embedding Shape: torch.Size([1, 768])\nsymptoms Embedding Shape: torch.Size([1, 768])\nexposure Embedding Shape: torch.Size([1, 768])\nmedical_history Embedding Shape: torch.Size([1, 768])\nmedications Embedding Shape: torch.Size([1, 768])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-4-db4d0fd03b55>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  lab_test_embeddings = torch.load(\"/kaggle/input/labreportandconversationembeddings/pytorch/default/1/lab_icd_embeddings.pt\")  # Lab report embeddings\n<ipython-input-4-db4d0fd03b55>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  conversation_data = torch.load(\"/kaggle/input/labreportandconversationembeddings/pytorch/default/1/conversation_embeddings_updated.pt\")  # Conversation embeddings\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch.nn as nn\n\n# Define new embedding size for richer representation\nd_f = 1024  \n\n# Define projection layers\nproj_lab = nn.Linear(768, d_f)  # Project lab embeddings to 1024\nproj_conv = nn.Linear(768, d_f)  # Project conversation embeddings to 1024\n\n# Apply projections to lab report embeddings\nfor test, info in lab_test_embeddings.items():\n    info[\"lab_test_embedding\"] = proj_lab(info[\"lab_test_embedding\"])  # Shape: (1, d_f)\n\n# Apply projections to conversation embeddings\nfor category, embedding in conversation_data[\"embeddings\"].items():\n    conversation_data[\"embeddings\"][category] = proj_conv(embedding)  # Shape: (1, d_f)\n\n# Verify new shapes\nfor test, info in lab_test_embeddings.items():\n    print(f\"Lab Test: {test} | Projected Embedding Shape: {info['lab_test_embedding'].shape}\")\n\nfor category, embedding in conversation_data[\"embeddings\"].items():\n    print(f\"{category} Projected Embedding Shape: {embedding.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T12:19:50.325993Z","iopub.execute_input":"2025-03-06T12:19:50.326359Z","iopub.status.idle":"2025-03-06T12:19:50.354992Z","shell.execute_reply.started":"2025-03-06T12:19:50.326322Z","shell.execute_reply":"2025-03-06T12:19:50.353954Z"}},"outputs":[{"name":"stdout","text":"Lab Test: The lab tests mentioned in the report are:\n\n1. Lipid Profile | Projected Embedding Shape: torch.Size([1, 1024])\nLab Test: Basic | Projected Embedding Shape: torch.Size([1, 1024])\nLab Test: Serum\n2. HbA1c (Glycosylated Hemoglobin) | Projected Embedding Shape: torch.Size([1, 1024])\nLab Test: Blood | Projected Embedding Shape: torch.Size([1, 1024])\nsymptoms Projected Embedding Shape: torch.Size([1, 1024])\nexposure Projected Embedding Shape: torch.Size([1, 1024])\nmedical_history Projected Embedding Shape: torch.Size([1, 1024])\nmedications Projected Embedding Shape: torch.Size([1, 1024])\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch.nn as nn\n\n'''\nMulti-head Attention is a module for attention mechanisms which runs through an attention mechanism \nseveral times in parallel. The independent attention outputs are then concatenated and linearly transformed\ninto the expected dimension. Intuitively, multiple attention heads allows for attending to parts of the sequence differently \n(e.g. longer-term dependencies versus shorter-term dependencies).\n\nLink jaha se padha : https://paperswithcode.com/method/multi-head-attention\n'''\n# Define Multihead Attention for Fusion\nmha = nn.MultiheadAttention(embed_dim=1024, num_heads=8)  # 8 heads for better representation\n\n# Apply fusion: Lab Test Embeddings + Symptoms Embeddings\nfor test, info in lab_test_embeddings.items():\n    if \"symptoms\" in conversation_data[\"embeddings\"]:  # Ensure symptoms embedding exists\n        lab_seq = info[\"lab_test_embedding\"].unsqueeze(0)  # Shape: (1, batch, 1024)\n        conv_seq = conversation_data[\"embeddings\"][\"symptoms\"].unsqueeze(0)  # Shape: (1, batch, 1024)\n\n        # Apply multihead attention: using lab test as query, conversation as key/value\n        attn_output, attn_weights = mha(query=lab_seq, key=conv_seq, value=conv_seq)\n\n        # Store fused embedding\n        info[\"fused_embedding\"] = attn_output.squeeze(0)  # Shape: (1, 1024)\n\n# Print final fused embeddings\nfor test, info in lab_test_embeddings.items():\n    if \"fused_embedding\" in info:\n        print(f\"Lab Test: {test} | Fused Embedding Shape: {info['fused_embedding'].shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T12:24:32.689715Z","iopub.execute_input":"2025-03-06T12:24:32.690058Z","iopub.status.idle":"2025-03-06T12:24:32.796015Z","shell.execute_reply.started":"2025-03-06T12:24:32.690031Z","shell.execute_reply":"2025-03-06T12:24:32.794710Z"}},"outputs":[{"name":"stdout","text":"Lab Test: The lab tests mentioned in the report are:\n\n1. Lipid Profile | Fused Embedding Shape: torch.Size([1, 1024])\nLab Test: Basic | Fused Embedding Shape: torch.Size([1, 1024])\nLab Test: Serum\n2. HbA1c (Glycosylated Hemoglobin) | Fused Embedding Shape: torch.Size([1, 1024])\nLab Test: Blood | Fused Embedding Shape: torch.Size([1, 1024])\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import torch.nn as nn\n\n# Creatin a Fully Connected Layer for passing fused embeddings created from Multihaed\nclass EnhancedFC(nn.Module):\n    def __init__(self, input_dim=1024, hidden_dim1=512, hidden_dim2=256, output_dim=256, dropout_prob=0.3):\n        super(EnhancedFC, self).__init__()\n\n        self.fc = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim1),\n            nn.LayerNorm(hidden_dim1),  # ✅ Use LayerNorm instead of BatchNorm\n            nn.ReLU(),\n            nn.Dropout(dropout_prob),\n\n            nn.Linear(hidden_dim1, hidden_dim2),\n            nn.LayerNorm(hidden_dim2),  # ✅ Use LayerNorm instead of BatchNorm\n            nn.ReLU(),\n            nn.Dropout(dropout_prob),\n\n            nn.Linear(hidden_dim2, output_dim)  # Final output (256-d embedding)\n        )\n\n    def forward(self, x):\n        return self.fc(x)\n\n# Initialize improved FC layer\nfc_model = EnhancedFC(input_dim=1024, output_dim=256)\n\n# Apply FC to all fused embeddings\nfor test, info in lab_test_embeddings.items():\n    if \"fused_embedding\" in info:\n        info[\"final_embedding\"] = fc_model(info[\"fused_embedding\"])  # Shape: (1, 256)\n\n# Print final transformed embeddings\nfor test, info in lab_test_embeddings.items():\n    if \"final_embedding\" in info:\n        print(f\"Lab Test: {test} | Final Embedding Shape: {info['final_embedding'].shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T12:58:24.441365Z","iopub.execute_input":"2025-03-06T12:58:24.441728Z","iopub.status.idle":"2025-03-06T12:58:24.492366Z","shell.execute_reply.started":"2025-03-06T12:58:24.441701Z","shell.execute_reply":"2025-03-06T12:58:24.491198Z"}},"outputs":[{"name":"stdout","text":"Lab Test: The lab tests mentioned in the report are:\n\n1. Lipid Profile | Final Embedding Shape: torch.Size([1, 256])\nLab Test: Basic | Final Embedding Shape: torch.Size([1, 256])\nLab Test: Serum\n2. HbA1c (Glycosylated Hemoglobin) | Final Embedding Shape: torch.Size([1, 256])\nLab Test: Blood | Final Embedding Shape: torch.Size([1, 256])\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}