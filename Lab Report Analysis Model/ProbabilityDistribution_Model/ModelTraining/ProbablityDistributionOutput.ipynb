{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-11T19:45:47.864705Z",
     "iopub.status.busy": "2025-02-11T19:45:47.864450Z",
     "iopub.status.idle": "2025-02-11T19:45:49.980797Z",
     "shell.execute_reply": "2025-02-11T19:45:49.980068Z",
     "shell.execute_reply.started": "2025-02-11T19:45:47.864669Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "final_df = pd.read_csv(r\"C:\\Users\\Anuj Bohra\\Desktop\\ArogoAI\\Severity\\combined_cleaned_df_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T19:45:54.333284Z",
     "iopub.status.busy": "2025-02-11T19:45:54.332940Z",
     "iopub.status.idle": "2025-02-11T19:45:55.004704Z",
     "shell.execute_reply": "2025-02-11T19:45:55.003897Z",
     "shell.execute_reply.started": "2025-02-11T19:45:54.333256Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "final_df = final_df.drop('Unnamed: 0', axis=1)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "gender_encoder = LabelEncoder()\n",
    "\n",
    "final_df['gender'] = gender_encoder.fit_transform(final_df['gender'])\n",
    "df_icd9 = final_df[final_df['icd_version'] == 9]\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "icd_encoded = encoder.fit_transform(df_icd9[['icd_code']])\n",
    "icd_encoded_df = pd.DataFrame(\n",
    "    icd_encoded,\n",
    "    columns=encoder.get_feature_names_out(['icd_code'])\n",
    ")\n",
    "X = df_icd9.drop(['hadm_id', 'icd_code', 'subject_id'], axis=1)\n",
    "y = icd_encoded_df\n",
    "y_labels = y.idxmax(axis=1)\n",
    "X.columns = X.columns.astype(str)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler() \n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "import numpy as np\n",
    "y_class = np.argmax(y.values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T20:00:10.054682Z",
     "iopub.status.busy": "2025-02-11T20:00:10.054334Z",
     "iopub.status.idle": "2025-02-11T20:00:40.438985Z",
     "shell.execute_reply": "2025-02-11T20:00:40.438051Z",
     "shell.execute_reply.started": "2025-02-11T20:00:10.054658Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Anuj Bohra\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:457\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(textwrap\u001b[38;5;241m.\u001b[39mdedent(\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;124m            Failed to load PyTorch C extensions:\u001b[39m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;124m                It appears that PyTorch has loaded the `torch/_C` folder\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;124m                or by running Python from a different directory.\u001b[39m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'''\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m  \u001b[38;5;66;03m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[1;32m--> 457\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(\u001b[43m_C\u001b[49m):\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBase\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    459\u001b[0m         __all__\u001b[38;5;241m.\u001b[39mappend(name)\n",
      "\u001b[1;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_size=25, hidden1=256, hidden2=512, hidden3=256, hidden4=128, num_classes=1203):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden2, hidden3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(hidden3, hidden4)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc5 = nn.Linear(hidden4, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.relu3(self.fc3(x))\n",
    "        x = self.relu4(self.fc4(x))\n",
    "        x = self.fc5(x)  # Raw logits (will apply softmax later)\n",
    "        return x\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2. Load the pre-trained models\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Load XGBoost model from a pickle file\n",
    "xgb_model_path = r'C:\\Users\\Anuj Bohra\\Desktop\\ArogoAI\\Severity\\Model\\xgb_model.pkl'  # Update with your actual file path\n",
    "loaded_xgb = joblib.load(xgb_model_path)\n",
    "\n",
    "# Load PyTorch model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pytorch_model_path = r'C:\\Users\\Anuj Bohra\\Desktop\\ArogoAI\\Severity\\Model\\simple_net_state_dict.pth'  # Update with your actual file path\n",
    "pytorch_model = SimpleNet(input_size=25, num_classes=1203).to(device)\n",
    "pytorch_model.load_state_dict(torch.load(pytorch_model_path, map_location=device))\n",
    "pytorch_model.eval()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3. Define the ensemble prediction functions\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def ensemble_predict(X, weights=None):\n",
    "    \"\"\"\n",
    "    Returns the ensemble's top-1 prediction for each sample.\n",
    "    This is useful for computing overall accuracy.\n",
    "    \n",
    "    Args:\n",
    "        X (np.array): Input feature array of shape (n_samples, n_features)\n",
    "        weights (list or tuple): Weights for the two models [w_xgb, w_pt].\n",
    "                                 Defaults to equal weighting if None.\n",
    "    \n",
    "    Returns:\n",
    "        final_preds (np.array): Array of shape (n_samples,) with the predicted class labels.\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = [1/2, 1/2]\n",
    "    w_xgb, w_pt = weights\n",
    "\n",
    "    # XGBoost: Get probability distribution\n",
    "    xgb_probs = loaded_xgb.predict_proba(X)  # Shape: (n_samples, num_classes)\n",
    "    \n",
    "    # PyTorch: Get probability distribution (apply softmax to logits)\n",
    "    X_tensor = torch.from_numpy(X).float().to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = pytorch_model(X_tensor)\n",
    "        pt_probs = F.softmax(outputs, dim=1).cpu().numpy()  # Shape: (n_samples, num_classes)\n",
    "    \n",
    "    # Compute weighted sum of probabilities\n",
    "    ensemble_probs =  w_xgb * xgb_probs + w_pt * pt_probs\n",
    "\n",
    "    # Return the class with the highest probability for each sample\n",
    "    final_preds = np.argmax(ensemble_probs, axis=1)\n",
    "    return final_preds\n",
    "\n",
    "def ensemble_topk(X, top_k=3, weights=None):\n",
    "    \"\"\"\n",
    "    Returns the top-k predictions (class indices and their probabilities) for each sample.\n",
    "    \n",
    "    Args:\n",
    "        X (np.array): Input feature array of shape (n_samples, n_features)\n",
    "        top_k (int): Number of top predictions to return.\n",
    "        weights (list or tuple): Weights for the two models [w_xgb, w_pt].\n",
    "                                 Defaults to equal weighting if None.\n",
    "    \n",
    "    Returns:\n",
    "        top_k_indices (np.array): Array of shape (n_samples, top_k) with top-k class indices.\n",
    "        top_k_probs (np.array): Array of shape (n_samples, top_k) with corresponding probabilities.\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = [1/2, 1/2]\n",
    "    w_xgb, w_pt = weights\n",
    "\n",
    "    # Get probability distributions from each model\n",
    "    xgb_probs = loaded_xgb.predict_proba(X)  # Shape: (n_samples, num_classes)\n",
    "    X_tensor = torch.from_numpy(X).float().to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = pytorch_model(X_tensor)\n",
    "        pt_probs = F.softmax(outputs, dim=1).cpu().numpy()  # Shape: (n_samples, num_classes)\n",
    "\n",
    "    # Compute weighted sum of probabilities\n",
    "    ensemble_probs =  w_xgb * xgb_probs + w_pt * pt_probs\n",
    "\n",
    "    # For each sample, retrieve the indices of the top k probabilities.\n",
    "    top_k_indices = np.argsort(ensemble_probs, axis=1)[:, -top_k:][:, ::-1]\n",
    "    top_k_probs = np.take_along_axis(ensemble_probs, top_k_indices, axis=1)\n",
    "    \n",
    "    return top_k_indices, top_k_probs\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4. Example usage\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Assuming X_scaled is your NumPy array of input features:\n",
    "# For instance:\n",
    "# X_scaled = np.load('X_scaled.npy')\n",
    "\n",
    "# # Get top-1 predictions (for accuracy computation)\n",
    "# final_predictions = ensemble_predict(X_scaled, weights=[0.4, 0.3, 0.3])\n",
    "# print(\"Final predictions (top-1) for each sample:\\n\", final_predictions)\n",
    "\n",
    "# # # Get top-3 predictions (with probabilities)\n",
    "# top_k_indices, top_k_probs = ensemble_topk(X_scaled, top_k=3, weights=[0.4, 0.3, 0.3])\n",
    "# print(\"Top-3 class indices for each sample:\\n\", top_k_indices)\n",
    "# print(\"Corresponding probabilities for top-3 predictions:\\n\", top_k_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T20:05:26.531893Z",
     "iopub.status.busy": "2025-02-11T20:05:26.531585Z",
     "iopub.status.idle": "2025-02-11T20:09:17.278726Z",
     "shell.execute_reply": "2025-02-11T20:09:17.277672Z",
     "shell.execute_reply.started": "2025-02-11T20:05:26.531866Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get top-1 predictions (for accuracy computation)\n",
    "final_predictions = ensemble_predict(X_scaled, weights=[0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T20:10:04.704220Z",
     "iopub.status.busy": "2025-02-11T20:10:04.703857Z",
     "iopub.status.idle": "2025-02-11T20:10:04.710522Z",
     "shell.execute_reply": "2025-02-11T20:10:04.709748Z",
     "shell.execute_reply.started": "2025-02-11T20:10:04.704189Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_class, final_predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T20:24:27.988896Z",
     "iopub.status.busy": "2025-02-11T20:24:27.988613Z",
     "iopub.status.idle": "2025-02-11T20:24:27.994298Z",
     "shell.execute_reply": "2025-02-11T20:24:27.993529Z",
     "shell.execute_reply.started": "2025-02-11T20:24:27.988875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tests = list(final_df.columns[5:])\n",
    "tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T20:24:39.235197Z",
     "iopub.status.busy": "2025-02-11T20:24:39.234898Z",
     "iopub.status.idle": "2025-02-11T20:24:39.267895Z",
     "shell.execute_reply": "2025-02-11T20:24:39.267215Z",
     "shell.execute_reply.started": "2025-02-11T20:24:39.235154Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "icd_codes = []\n",
    "for i in y.columns:\n",
    "    icd_codes.append(i[9:])\n",
    "icd_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T20:28:33.544805Z",
     "iopub.status.busy": "2025-02-11T20:28:33.544527Z",
     "iopub.status.idle": "2025-02-11T20:28:33.712052Z",
     "shell.execute_reply": "2025-02-11T20:28:33.711398Z",
     "shell.execute_reply.started": "2025-02-11T20:28:33.544784Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "icd_df = pd.read_csv(r'C:\\Users\\Anuj Bohra\\Desktop\\ArogoAI\\Severity\\d_icd_diagnoses.csv')\n",
    "icd_df = icd_df[icd_df['icd_version'] == 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T20:28:36.738754Z",
     "iopub.status.busy": "2025-02-11T20:28:36.738480Z",
     "iopub.status.idle": "2025-02-11T20:28:36.747954Z",
     "shell.execute_reply": "2025-02-11T20:28:36.747160Z",
     "shell.execute_reply.started": "2025-02-11T20:28:36.738734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "icd_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T20:33:26.206601Z",
     "iopub.status.busy": "2025-02-11T20:33:26.206309Z",
     "iopub.status.idle": "2025-02-11T20:37:15.577072Z",
     "shell.execute_reply": "2025-02-11T20:37:15.576415Z",
     "shell.execute_reply.started": "2025-02-11T20:33:26.206580Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Get top-3 predictions (with probabilities)\n",
    "top_k_indices, top_k_probs = ensemble_topk(X_scaled, top_k=3, weights=[0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T20:42:00.220001Z",
     "iopub.status.busy": "2025-02-11T20:42:00.219685Z",
     "iopub.status.idle": "2025-02-11T20:42:00.225217Z",
     "shell.execute_reply": "2025-02-11T20:42:00.224583Z",
     "shell.execute_reply.started": "2025-02-11T20:42:00.219974Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "top_k_probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T20:48:06.341755Z",
     "iopub.status.busy": "2025-02-11T20:48:06.341436Z",
     "iopub.status.idle": "2025-02-11T20:48:06.397801Z",
     "shell.execute_reply": "2025-02-11T20:48:06.397086Z",
     "shell.execute_reply.started": "2025-02-11T20:48:06.341728Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def format_ensemble_predictions(top_k_indices, y_labels, icd_df, top_k_probs):\n",
    "    \"\"\"\n",
    "    Given an array of top k prediction indices for each sample,\n",
    "    a list of y_labels mapping indices to ICD codes, and a dataframe containing\n",
    "    ICD code details (with columns \"icd_code\" and \"long_title\"), returns a list\n",
    "    of formatted strings describing the predictions in natural language.\n",
    "\n",
    "    Args:\n",
    "        top_k_indices (np.array): Array of shape (n_samples, top_k) with predicted class indices.\n",
    "        y_labels (list): List of ICD code strings, mapping model output indices to ICD codes.\n",
    "        icd_df (pd.DataFrame): DataFrame with columns \"icd_code\" and \"long_title\".\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: A list of formatted strings, one for each sample.\n",
    "    \"\"\"\n",
    "    formatted_outputs = []\n",
    "    n_samples, top_k = top_k_indices.shape\n",
    "    \n",
    "    for i in range(1):\n",
    "        # Convert predicted indices to ICD codes.\n",
    "        predicted_codes = [y_labels[idx] for idx in top_k_indices[i]]\n",
    "        # Lookup the long_title for each ICD code.\n",
    "        titles = []\n",
    "        probs = []\n",
    "        ct = 0\n",
    "        for code in predicted_codes:\n",
    "            # Find the row with the matching ICD code.\n",
    "            match = icd_df[icd_df['icd_code'] == code]\n",
    "            if not match.empty:\n",
    "                title = match.iloc[0]['long_title']\n",
    "            else:\n",
    "                title = \"Unknown condition\"\n",
    "            titles.append(title)\n",
    "            probs.append(top_k_probs[i][ct])\n",
    "            ct+=1\n",
    "        \n",
    "        # Format a natural language string.\n",
    "        formatted_str = f\"Sample {i+1}: The top {top_k} predicted diagnoses are:\\n\"\n",
    "        for rank, (code, title) in enumerate(zip(predicted_codes, titles), start=1):\n",
    "            prob_this = float(\"{:.2f}\".format(probs[rank-1]*100))\n",
    "            formatted_str += f\"  {rank}. {title} (ICD Code: {code}) with Probability : {prob_this}%\\n\"\n",
    "        \n",
    "        formatted_outputs.append(formatted_str)\n",
    "        \n",
    "    return formatted_outputs\n",
    "\n",
    "# Example usage:\n",
    "# Assume top_k_indices is obtained from ensemble_topk, y_labels is your list of ICD codes,\n",
    "# and icd_df is your DataFrame.\n",
    "formatted_results = format_ensemble_predictions(top_k_indices, icd_codes, icd_df, top_k_probs)\n",
    "\n",
    "# Print the formatted output for each sample.\n",
    "for result in formatted_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_df[icd_df['icd_code'] == '5723']['long_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# 1. Compute the Confusion Matrix (for the top prediction)\n",
    "conf_matrix = confusion_matrix(y_class, top_k_indices[:, 0])  # Compare true labels with the top-1 predictions\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# 2. Compute Top-K Accuracy\n",
    "# For top-3 accuracy, we check if the true label is in the top 3 predictions for each sample\n",
    "top_k_accuracy = np.mean([y_class[i] in top_k_indices[i] for i in range(len(y_class))])\n",
    "print(f\"Top-3 Accuracy: {top_k_accuracy * 100:.2f}%\")\n",
    "\n",
    "# If you also want to calculate top-1 accuracy (which is simple accuracy):\n",
    "top_1_accuracy = accuracy_score(y_class, top_k_indices[:, 0])\n",
    "print(f\"Top-1 Accuracy: {top_1_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_importance = loaded_xgb.get_booster().get_score(importance_type='weight')\n",
    "importances_df = pd.DataFrame(list(xgb_importance.items()), columns=['Feature', 'Importance'])\n",
    "importances_df = importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot top features\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importances_df['Feature'][:20], importances_df['Importance'][:20])  # Top 20 features\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"XGBoost Feature Importance\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# to extract names of features instead of numbers\n",
    "feature_names = X.columns  \n",
    "xgb_importance = loaded_xgb.get_booster().get_score(importance_type='weight')\n",
    "\n",
    "#dataframe for plottting\n",
    "importances_df = pd.DataFrame({\n",
    "    'Feature': [feature_names[int(k[1:])] if k[1:].isdigit() else k for k in xgb_importance.keys()],  # Convert indices to names\n",
    "    'Importance': list(xgb_importance.values())\n",
    "})\n",
    "importances_df = importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot top features\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importances_df['Feature'][:20], importances_df['Importance'][:20])  # 20 features ka \n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"XGBoost Feature Importance\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_df = pd.read_csv(r'C:\\Users\\Anuj Bohra\\Desktop\\ArogoAI\\Severity\\d_labitems.csv')\n",
    "lab_test_name = lab_df[lab_df['itemid'] == 51265]\n",
    "print(lab_test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "# Set ensemble weights\n",
    "w_xgb = 0.4\n",
    "w_pt = 0.3\n",
    "\n",
    "# Define the sample (assuming X_test[0] is the sample)\n",
    "single_sample = X_scaled[0:1]  # Shape: (1, num_features)\n",
    "single_sample_tensor = torch.tensor(single_sample, dtype=torch.float32).to(device)\n",
    "\n",
    "# -------------------- 1. SHAP for XGBoost --------------------\n",
    "explainer_xgb = shap.TreeExplainer(loaded_xgb)\n",
    "shap_values_xgb = explainer_xgb.shap_values(single_sample)[0]  # Shape: (num_features,)\n",
    "\n",
    "# -------------------- 2. Integrated Gradients for NN --------------------\n",
    "ig = IntegratedGradients(pytorch_model)\n",
    "baseline = torch.zeros_like(single_sample_tensor)  # Baseline (zero input)\n",
    "attr, _ = ig.attribute(single_sample_tensor, baseline, target=None, return_convergence_delta=True)\n",
    "attr = attr.cpu().detach().numpy().flatten()  # Convert to NumPy\n",
    "\n",
    "# -------------------- 3. Weight & Combine Importance --------------------\n",
    "combined_importance = (w_xgb * shap_values_xgb) + (w_pt * attr)\n",
    "\n",
    "# -------------------- 4. Waterfall Plot --------------------\n",
    "feature_names = [f\"Feature {i}\" for i in range(single_sample.shape[1])]\n",
    "\n",
    "shap.waterfall_plot(shap.Explanation(\n",
    "    values=combined_importance,\n",
    "    base_values=0,  # Adjust if needed\n",
    "    feature_names=feature_names\n",
    "))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6646532,
     "sourceId": 10722068,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6649440,
     "sourceId": 10725968,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6649528,
     "sourceId": 10726089,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
